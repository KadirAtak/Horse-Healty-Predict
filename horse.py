# -*- coding: utf-8 -*-
"""horse

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1waSLo-VOpEziv5PuRc_JWyqUnyw7pH3A
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.subplots as ps
from sklearn.metrics import classification_report
from sklearn.ensemble import ExtraTreesClassifier
from keras.utils import to_categorical, plot_model

train_data = pd.read_csv("train.csv")
test_data = pd.read_csv("test.csv")
pd.set_option( "display.max_columns", None)

test_data.head()

train_data.head()

train_data = train_data[train_data.columns[1:]]
test_data = test_data[test_data.columns[1:]]

numeric_train = train_data.select_dtypes(include=['float'])
Classify_train = train_data.select_dtypes(exclude = ['float'])

numeric_test = test_data.select_dtypes(include =('float'))
Classify_test = test_data.select_dtypes(exclude = ['float'])

Classify_train = Classify_train.drop("hospital_number",axis = 1)
Classify_test = Classify_test.drop("hospital_number",axis = 1)

Classify_train = Classify_train.fillna("unknown")
Classify_test = Classify_test.fillna("unknown")

numerical_1 = train_data.select_dtypes(exclude=['object'])
numerical_cols = train_data.select_dtypes(exclude=['object']).columns.tolist()
numerical_cols
for col in numerical_cols:
    train_data = train_data.drop(columns=col)
train_data.shape

Classify_train['Count'] = 1
Classify_train_dpone = Classify_train.drop('lesion_1',axis = 1)
Analysis_class = pd.get_dummies(Classify_train_dpone, columns = ['outcome'])
Analysis_class = Analysis_class.rename(columns = {'outcome_died' : 'died', 'outcome_euthanized' : 'euthanized', 'outcome_lived' : 'lived'})

dict_outcome = {True : 1, False : 0 }
for col in Analysis_class.columns[-3:]:
    Analysis_class[col] = Analysis_class[col].replace(dict_outcome)

numeric_ot_train = pd.concat([numeric_train, Analysis_class[Analysis_class.columns[-4:]]],axis = 1)
numeric_ot_train

Classify_train_data = Classify_train.drop(columns = ['Count','outcome'])
Classify_test_data = Classify_test
target_outcome = Classify_train['outcome']

from sklearn.preprocessing import OneHotEncoder, LabelEncoder
Normal_target = LabelEncoder()
target= Normal_target.fit_transform(target_outcome)

from sklearn.preprocessing import OneHotEncoder, LabelEncoder
Class_enc = OneHotEncoder(handle_unknown = 'ignore')
C_train_data = Class_enc.fit_transform(Classify_train_data).toarray()
C_test_data = Class_enc.transform(Classify_test_data).toarray()
print(f'The Classify train data shape : {C_train_data .shape}')
print(f'The Classify test data shape : {C_test_data .shape}')

N_train_data = numeric_train.to_numpy()
N_test_data = numeric_test.to_numpy()
print(f'The Numeric train data shape : {N_train_data.shape}')
print(f'The Numeric test data shape : {N_test_data.shape}')

CN_train_data = np.concatenate([C_train_data,N_train_data], axis = 1)
CN_test_data = np.concatenate([C_test_data, N_test_data], axis = 1)
print(f' The Classify + Numeric train data of shape : {CN_train_data.shape}')
print(f' The Classify + Numeric test data of shape : {CN_test_data.shape}')

from sklearn.model_selection import train_test_split
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

x_train, x_test, y_train, y_test = train_test_split(CN_train_data, target, train_size=0.9, random_state=58)

y_train_encoded = to_categorical(y_train)
y_test_encoded = to_categorical(y_test)

print("x_train.shape:", x_train.shape)
print("y_train_encoded.shape:", y_train_encoded.shape)
print("x_test.shape:", x_test.shape)
print("y_test_encoded.shape:", y_test_encoded.shape)

mlp_C = Sequential()
mlp_C.add(Dense(32, activation='relu', input_dim=x_train.shape[1]))
mlp_C.add(Dense(32, activation='relu'))
mlp_C.add(Dense(32, activation='relu'))
mlp_C.add(Dense(32, activation='relu'))
mlp_C.add(Dense(16, activation='relu'))
mlp_C.add(Dense(16, activation='relu'))
mlp_C.add(Dense(16, activation='relu'))
mlp_C.add(Dense(3, activation='softmax'))
mlp_C.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history = mlp_C.fit(x_train, y_train_encoded, epochs=50, batch_size=256, validation_split=0.1)

import matplotlib.pyplot as plt
df_DL = pd.DataFrame(history.history)
df_DL.head()
plt.plot(df_DL.index, df_DL['loss'], label = 'loss')
plt.plot(df_DL.index, df_DL['val_loss'], label = 'Val_loss')
plt.xlabel( 'Epochs')
plt.ylabel('crossentropy')
plt.title('DL loss function')
plt.legend()

predictions = mlp_C.predict(x_test)

predicted_classes = np.argmax(predictions, axis=1)

from sklearn.metrics import classification_report
print(classification_report(y_test, predicted_classes))

predictions = mlp_C.predict(CN_test_data)
for i in range(100):
    print("Gerçek Değer:", y_test[i], "Tahmin:", np.argmax(predictions[i]))

prediction = mlp_C.predict(CN_test_data)
predicted_classes = np.argmax(prediction, axis=1)
predicted_labels = Normal_target.inverse_transform(predicted_classes)
submission = pd.read_csv('sample_submission.csv')
submission["outcome"] = predicted_labels
submission.to_csv('submission_C.csv', index=False)

mlp_B = Sequential()
mlp_B.add(Dense(64, activation='relu', input_dim=x_train.shape[1]))
mlp_B.add(Dense(64, activation='relu'))
mlp_B.add(Dense(64, activation='relu'))
mlp_B.add(Dense(64, activation='relu'))
mlp_B.add(Dense(32, activation='relu'))
mlp_B.add(Dense(32, activation='relu'))
mlp_B.add(Dense(32, activation='relu'))
mlp_B.add(Dense(32, activation='relu'))
mlp_B.add(Dense(3, activation='softmax'))
mlp_B.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_B = mlp_B.fit(x_train, y_train_encoded, epochs=50, batch_size=256, validation_split=0.1)

import matplotlib.pyplot as plt
df_DL = pd.DataFrame(history_B.history)
df_DL.head()
plt.plot(df_DL.index, df_DL['loss'], label = 'loss')
plt.plot(df_DL.index, df_DL['val_loss'], label = 'Val_loss')
plt.xlabel( 'Epochs')
plt.ylabel('crossentropy')
plt.title('DL loss function')
plt.legend()

predictions = mlp_B.predict(x_test)
predicted_classes = np.argmax(predictions, axis=1)
from sklearn.metrics import classification_report
print(classification_report(y_test, predicted_classes))

prediction = mlp_B.predict(CN_test_data)
predicted_classes = np.argmax(prediction, axis=1)
predicted_labels = Normal_target.inverse_transform(predicted_classes)
submission = pd.read_csv('sample_submission.csv')
submission["outcome"] = predicted_labels
submission.to_csv('submission_B.csv', index=False)

mlp_A = Sequential()
mlp_A.add(Dense(256, activation='relu', input_dim=x_train.shape[1]))
mlp_A.add(Dense(128, activation='relu'))
mlp_A.add(Dense(64, activation='relu'))
mlp_A.add(Dense(32, activation='relu'))
mlp_A.add(Dense(128, activation='relu'))
mlp_A.add(Dense(64, activation='relu'))
mlp_A.add(Dense(32, activation='relu'))
mlp_A.add(Dense(128, activation='relu'))
mlp_A.add(Dense(64, activation='relu'))
mlp_A.add(Dense(32, activation='relu'))
mlp_A.add(Dense(3, activation='softmax'))
mlp_A.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
history_A = mlp_A.fit(x_train, y_train_encoded, epochs=50, batch_size=256, validation_split=0.1)

import matplotlib.pyplot as plt
df_DL = pd.DataFrame(history_A.history)
df_DL.head()
plt.plot(df_DL.index, df_DL['loss'], label = 'loss')
plt.plot(df_DL.index, df_DL['val_loss'], label = 'Val_loss')
plt.xlabel( 'Epochs')
plt.ylabel('crossentropy')
plt.title('DL loss function')
plt.legend()

predictions = mlp_A.predict(x_test)
predicted_classes = np.argmax(predictions, axis=1)
from sklearn.metrics import classification_report
print(classification_report(y_test, predicted_classes))

prediction = mlp_A.predict(CN_test_data)
predicted_classes = np.argmax(prediction, axis=1)
predicted_labels = Normal_target.inverse_transform(predicted_classes)
submission = pd.read_csv('sample_submission.csv')
submission["outcome"] = predicted_labels
submission.to_csv('submission_A.csv', index=False)